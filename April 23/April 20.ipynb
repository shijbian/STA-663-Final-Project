{
 "metadata": {
  "name": "",
  "signature": "sha256:5db123488be03c62e4b2f0f2a7230607acd2f3d5109885df2d1a6c030bf32a24"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bayesian Hierarchical Clustering \n",
      "============="
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Abstract\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Outline"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Background\n",
      "\n",
      "State the research paper you are using. Describe the concept of the algorithm and why it is interesting and/or useful. If appropriate, describe the mathematical basis of the algorithm. Some potential topics for the backgorund include:\n",
      "\n",
      "- What problem does it address? \n",
      "- What are known and possible applications of the algorithm? \n",
      "- What are its advantages and disadvantages relative to other algorithms?\n",
      "- How will you use it in your research?\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Basic Algorithm\n",
      "\n",
      "\n",
      "**input** data $\\mathcal{D} = {x^{(1)}, x^{(2)}, \\ldots, x^{(n)}}$, model $p(x|\\theta)$, prior $p(\\theta|\\beta)$\n",
      "\n",
      "**initialize: ** number of clusters $\\mathcal{c}=\\mathcal{n}$ for $i = 1, \\ldots, n$\n",
      "\n",
      "**while** $\\mathcal{c}>1$ **do**:\n",
      "\n",
      "+ Find the pair $\\mathcal{D}_i$ and $\\mathcal{D}_j$ with the highest probability of the merged hypothesis:\n",
      " $$\\mathcal{r}_k = \\frac{\\pi_k p(\\mathcal{D}_k|\\mathcal{H}_1^k)}{p(\\mathcal{D}_k|\\mathcal{T}_k)}$$\n",
      "+ Merge $\\mathcal{D}_k \\leftarrow \\mathcal{D}_i \\cup \\mathcal{D}_j$, $\\mathcal{T}_k \\leftarrow (\\mathcal{T}_i, \\mathcal{T}_j)$\n",
      "+ Delete $\\mathcal{D}_i$ and $\\mathcal{D}_j$, $c \\leftarrow c-1$\n",
      "\n",
      "**end while**\n",
      "\n",
      "**output: ** Bayesian mixture model where each tree node is a mixture component\n",
      "The tree can be cut at points where $\\mathcal{r}_k<0.5$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Case Study I: Gaussion Distribution with Unknown Mean and Precision\n",
      "\n",
      "Assume each observation $x^{(i)}$ consists of $d$ variables, i.e.$x^{(i)}=(x_1^{(i)},\\ldots,x_d^{(i)})$, we need make the assumptions below to accomodate the algorithm:\n",
      "\n",
      "+ the dataset is normalized, i.e. it has mean sero and a unit variance;\n",
      "+ for each observation $x^{(i)}$,its variables ${x_j^{(i)}}_{j=1}^d$ are independnt and generated from different Gaussian distributions.\n",
      "+ the realizations of each variable j, ${x_j^{(i)}}_{j=1}^{n_k}$ in cluster $\\mathcal{D}_k$ are independent and identically distributed and drawn from Gaussian distribution with unknown mean $\\mu_j$ and precision $\\sigma_j^2$, and the prior on $(\\mu_j,\\sigma_j^{-2})$ is a normal-gamma distribution with hyperparameter $\\mu_0,\\sigma_0,\\beta_0,\\kappa$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import scipy.stats as stats\n",
      "from IPython.core.pylabtools import figsize\n",
      "import numpy as np\n",
      "figsize(12.5, 4)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "%matplotlib inline\n",
      "import scipy.stats as stats\n",
      "from IPython.core.pylabtools import figsize\n",
      "import numpy as np\n",
      "figsize(12.5, 4)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "import itertools\n",
      "\n",
      "import numpy as np\n",
      "from scipy import linalg\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "\n",
      "from sklearn import mixture"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Simulate data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean = (1,2)\n",
      "cov = [[1,0],[0,1]]\n",
      "dat = np.random.multivariate_normal(mean,cov,100)\n",
      "print dat.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 2)\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Code the algorithm "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class cluster_node:\n",
      "    def __init__(self,vec,left=None,right=None,distance=0.0,id=None,count=1):\n",
      "        self.left=left\n",
      "        self.right=right\n",
      "        self.vec=vec\n",
      "        self.id=id\n",
      "        self.distance=distance\n",
      "        self.count=count #only used for weighted average "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def likelihood (data, d):\n",
      "    likelihood = 1\n",
      "    for j in range(0,d):\n",
      "        chi_0 = 1\n",
      "        n_k = nth cluster's size\n",
      "        chi_nk = chi_0 + n_k\n",
      "        \n",
      "        lambda_0 = 1\n",
      "        lambda_nk = lambda_0 + n_k*1.0/2\n",
      "        x_j_bar\n",
      "        \n",
      "        beta_0 = 1\n",
      "        beta_nk = beta_0 + 0.5*(variance of jth cluster + chi_0*n_k + mean of jth cluster)\n",
      "        \n",
      "        partialLik = (gamma(lambda_nk)*1.0/gamma(lambda_0))*(pow(beta_0,lambda_0)/pow(beta_nk,lambda_nk))*pow((chi_0*1.0/chi_nk),0.5)*pow(2*pi,-n_k*1.0/2)\n",
      "        likelihood = likelihood * partialLik\n",
      "    return likelihood\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hcluster(features, distance=likelihood):\n",
      "    #cluster the rows of the \"features\" matrix\n",
      "    distances={}\n",
      "    currentclustid=-1\n",
      "\n",
      "    # clusters are initially just the individual rows\n",
      "    clust=[cluster_node(array(features[i]),id=i) for i in range(len(features))]\n",
      "    \n",
      "    while len(clust)>1:\n",
      "        lowestpair=(0,1)\n",
      "        closest=distance(clust[0].vec,clust[1].vec)\n",
      "\n",
      "        # loop through every pair looking for the smallest distance\n",
      "        for i in range(len(clust)):\n",
      "            for j in range(i+1,len(clust)):\n",
      "                # distances is the cache of distance calculations\n",
      "                if (clust[i].id,clust[j].id) not in distances: \n",
      "                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n",
      "\n",
      "                d=distances[(clust[i].id,clust[j].id)]\n",
      "\n",
      "                if d < 0.5:\n",
      "                    closest=d\n",
      "                    lowestpair=(i,j)\n",
      "\n",
      "        # calculate the average of the two clusters\n",
      "        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 \\\n",
      "            for i in range(len(clust[0].vec))]\n",
      "\n",
      "        # create the new cluster\n",
      "        newcluster=cluster_node(array(mergevec),left=clust[lowestpair[0]],\n",
      "                             right=clust[lowestpair[1]],\n",
      "                             distance=closest,id=currentclustid)\n",
      "\n",
      "        # cluster ids that weren't in the original set are negative\n",
      "        currentclustid-=1\n",
      "        del clust[lowestpair[1]]\n",
      "        del clust[lowestpair[0]]\n",
      "        clust.append(newcluster)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'likelihood' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-10-3405bf2d73f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mhcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mclust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mlowestpair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mclosest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'likelihood' is not defined"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class cluster_node:\n",
      "    def __init__(self,vec,left=None,right=None,distance=0.0,id=None,count=1):\n",
      "        self.left=left\n",
      "        self.right=right\n",
      "        self.vec=vec\n",
      "        self.id=id\n",
      "        self.distance=distance\n",
      "        self.count=count #only used for weighted average \n",
      "        \n",
      "\n",
      "def likelihood(v1,v2):\n",
      "    return sqrt(sum((v1-v2)**2))\n",
      "\n",
      "def hcluster(data, features, distance=likelihood):\n",
      "    #cluster the rows of the \"features\" matrix\n",
      "    distances={}\n",
      "    currentclustid=-1\n",
      "\n",
      "    # clusters are initially just the individual rows\n",
      "    clust=[cluster_node(array(features[i]),id=i) for i in range(len(features))]\n",
      "    \n",
      "    while len(clust)>1:\n",
      "        lowestpair=(0,1)\n",
      "        closest=distance(clust[0].vec,clust[1].vec)\n",
      "\n",
      "        # loop through every pair looking for the smallest distance\n",
      "        for i in range(len(clust)):\n",
      "            for j in range(i+1,len(clust)):\n",
      "                # distances is the cache of distance calculations\n",
      "                if (clust[i].id,clust[j].id) not in distances: \n",
      "                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n",
      "\n",
      "                d=distances[(clust[i].id,clust[j].id)]\n",
      "\n",
      "                if d < 0.5:\n",
      "                    closest=d\n",
      "                    lowestpair=(i,j)\n",
      "\n",
      "        # calculate the average of the two clusters\n",
      "        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 for i in range(0,clust[0].vec)]\n",
      "\n",
      "        # create the new cluster\n",
      "        newcluster=cluster_node(array(mergevec),left=clust[lowestpair[0]],\n",
      "                             right=clust[lowestpair[1]],\n",
      "                             distance=closest,id=currentclustid)\n",
      "\n",
      "        # cluster ids that weren't in the original set are negative\n",
      "        currentclustid-=1\n",
      "        del clust[lowestpair[1]]\n",
      "        del clust[lowestpair[0]]\n",
      "\n",
      "        clust.append(newcluster)\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "unexpected character after line continuation character (<ipython-input-33-7d5db0a4733a>, line 40)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-7d5db0a4733a>\"\u001b[1;36m, line \u001b[1;32m40\u001b[0m\n\u001b[1;33m    mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 \\\u001b[0m\n\u001b[1;37m                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean = (1,2)\n",
      "cov = [[1,0],[0,1]]\n",
      "dat = np.random.multivariate_normal(mean,cov,100)\n",
      "print dat.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 2)\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hcluster(dat[:,0], features = range(0,3), distance=likelihood)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "too many indices for array",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-31-673abf959dfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-29-151f194d8105>\u001b[0m in \u001b[0;36mhcluster\u001b[1;34m(data, features, distance)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# calculate the average of the two clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mmergevec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlowestpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlowestpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2.0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# create the new cluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dat[:,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.88986863  0.96007265  2.38736272  0.70263551  1.12231456  0.57346145\n",
        "  0.54719191 -0.04288336 -0.21837376  3.12630354  1.99938507  1.92215768\n",
        "  0.15075402 -0.50349401  0.36544073  0.11863046  0.40824493  1.8046679\n",
        "  2.78266929  0.74816034  2.09968715 -0.57785165 -0.92562716  2.24965709\n",
        "  0.89273381  2.51820003  0.56792417 -0.18042446  0.06310434  1.25527837\n",
        " -0.06422395  0.42262529 -0.00769153  1.80305154 -0.14768738  1.93739494\n",
        "  1.31987066 -0.12972653  1.86907964  0.65541696  1.60990185  0.89316314\n",
        "  0.94993194 -0.45130526  1.43298047  1.85817829  1.85189182  1.78688825\n",
        "  2.09597041  1.42265182  2.04900075  1.17064586  1.68594198  0.66420918\n",
        "  0.48269293  2.30630714 -1.20654236  0.46663135  1.28889076  1.34374616\n",
        "  0.71959748  1.4099451   1.86920622  1.9573699   1.61036237  1.28209669\n",
        "  1.5630093   1.49354159  0.90409212 -0.55123506 -0.54148967  1.76598772\n",
        "  0.91414739  1.81804222 -0.60928405  0.37661988  1.56192684 -0.73224503\n",
        "  2.67916955  0.21141596  2.07908695 -0.87339725  1.63513866  2.07047243\n",
        "  2.69543868 -2.06792404  3.10345623  2.59196697  1.5306412   1.2073906\n",
        "  0.89529603  1.11404754  0.62792274  2.40520647  0.82719572 -1.32261979\n",
        "  1.44140871  2.30115356  1.04354586 -0.42336101]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = range(0,3)\n",
      "clust=[cluster_node(array(features[i]),id=i) for i in range(len(range(0,3)))]\n",
      "print len(clust)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = range(0,3)\n",
      "features[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hcluster(data, features):\n",
      "    #cluster the rows of the \"features\" matrix\n",
      "    distances=[]\n",
      "    currentclustid=-1\n",
      "    dim = data.shape[0]\n",
      "    \n",
      "    newDic = zip(range(dat.shape[0]), dat[:,0])\n",
      "    newDic[3][0]\n",
      "\n",
      "    # clusters are initially just the individual rows\n",
      "    clust = range(0,dim)\n",
      "    while len(clust) > 1:\n",
      "        for i in range(len(clust)):\n",
      "            for j in range(i+1,len(clust)):\n",
      "                if ((i,j) not in distances == TRUE): \n",
      "                    distances.append((i,j))\n",
      "                    \n",
      "                d = distance()\n",
      "'''\n",
      "    while len(clust)>1:\n",
      "        lowestpair=(0,1)\n",
      "        closest=distance(clust[0].vec,clust[1].vec)\n",
      "\n",
      "        # loop through every pair looking for the smallest distance\n",
      "        for i in range(len(clust)):\n",
      "            for j in range(i+1,len(clust)):\n",
      "                # distances is the cache of distance calculations\n",
      "                if (clust[i].id,clust[j].id) not in distances: \n",
      "                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n",
      "\n",
      "                d=distances[(clust[i].id,clust[j].id)]\n",
      "\n",
      "                if d < 0.5:\n",
      "                    closest=d\n",
      "                    lowestpair=(i,j)\n",
      "\n",
      "        # calculate the average of the two clusters\n",
      "        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 for i in range(0,clust[0].vec)]\n",
      "\n",
      "        # create the new cluster\n",
      "        newcluster=cluster_node(array(mergevec),left=clust[lowestpair[0]],\n",
      "                             right=clust[lowestpair[1]],\n",
      "                             distance=closest,id=currentclustid)\n",
      "\n",
      "        # cluster ids that weren't in the original set are negative\n",
      "        currentclustid-=1\n",
      "        del clust[lowestpair[1]]\n",
      "        del clust[lowestpair[0]]\n",
      "\n",
      "        clust.append(newcluster)\n",
      "        \n",
      "'''\n",
      "hcluster(dat, features=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "range(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "[0, 1, 2, 3]"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newDic = zip(range(dat.shape[0]), dat[:,0])\n",
      "newDic[3][0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distances=[]\n",
      "distances.append((1,2))\n",
      "distances.append((5,2))\n",
      "distances[(5,2)] =3\n",
      "print (5,2) not in distances == TRUE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "list indices must be integers, not tuple",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-59-0c3fb2b80aae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdistances\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTRUE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: list indices must be integers, not tuple"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create Data Points "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean = (1,20)\n",
      "cov = [[1,0],[0,10]]\n",
      "dat = np.random.multivariate_normal(mean,cov,100)\n",
      "print dat.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 2)\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reshape the dataset to be a 20*1 \n",
      "data = dat.reshape((200, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(data, bins=20, color=\"k\", histtype=\"stepfilled\", alpha=0.8)\n",
      "plt.title(\"Histogram of the dataset\")\n",
      "plt.ylim([0, None])\n",
      "print data[:10], \"...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  0.13596385]\n",
        " [ 16.84085229]\n",
        " [  1.69210384]\n",
        " [ 23.57975785]\n",
        " [  0.77018732]\n",
        " [ 23.03081598]\n",
        " [  0.33644343]\n",
        " [ 19.65513529]\n",
        " [  0.55287434]\n",
        " [ 19.21725504]] ...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAEKCAYAAADO5On4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMUO3JEmS1Nj/Bx5jExPssJ8DAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff4d311ad10>"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymc as pm\n",
      "\n",
      "p = pm.Uniform(\"p\", 0, 1)\n",
      "\n",
      "assignment = pm.Categorical(\"assignment\", [p, 1 - p], size=data.shape[0])\n",
      "print \"prior assignment, with p = %.2f:\" % p.value\n",
      "print assignment.value[:10], \"...\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "prior assignment, with p = 0.66:\n",
        "[0 0 0 0 0 0 0 0 0 0] ...\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print assignment.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0\n",
        " 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1\n",
        " 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1\n",
        " 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1\n",
        " 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0\n",
        " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0]\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "value = np.array([assignment.value])\n",
      "value = value.reshape((200,1)).reshape(-1)\n",
      "df = pd.DataFrame({'data': data.reshape(-1),\n",
      "                   'Assignment': value}, index=range(0,200))\n",
      "df['Assignment'] = df['Assignment'].astype(object)\n",
      "grouped = df.groupby(\"Assignment\")\n",
      "grouped.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Assignment</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 10.779774</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  9.899309</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "                 data\n",
        "Assignment           \n",
        "0           10.779774\n",
        "1            9.899309"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Slice the two data frames\n",
      "# df_0 has the data labeled 0\n",
      "# df_1 has the data labeled 1\n",
      "\n",
      "df_0 = df.loc[df['Assignment'] == 0]\n",
      "df_1 = df.loc[df['Assignment'] == 1]\n",
      "\n",
      "df_0.head()\n",
      "df_1.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Assignment</th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 1</td>\n",
        "      <td> 18.176113</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> 1</td>\n",
        "      <td>  1.759521</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> 1</td>\n",
        "      <td>  0.576100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td> 1</td>\n",
        "      <td>  1.816936</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td> 1</td>\n",
        "      <td> 18.529269</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "   Assignment       data\n",
        "15          1  18.176113\n",
        "20          1   1.759521\n",
        "22          1   0.576100\n",
        "24          1   1.816936\n",
        "27          1  18.529269"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rows_0_v: random select two data from df_0\n",
      "rows_0 = np.random.choice(df_0.index.values, 2)\n",
      "sampled_df_0 = df.ix[rows_0]\n",
      "sampled_df_0\n",
      "rows_0_v = rows_0.reshape(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 148,
       "text": [
        "array([ 97, 196])"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rows_1_v: random select two data from df_1\n",
      "rows_1 = np.random.choice(df_1.index.values, 2)\n",
      "sampled_df_1 = df.ix[rows_1]\n",
      "sampled_df_1\n",
      "rows_1_v = rows_1.reshape(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 147,
       "text": [
        "array([39, 43])"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampled_df_0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Assignment</th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>97 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 19.87261</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>196</th>\n",
        "      <td> 0</td>\n",
        "      <td>  1.20387</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "    Assignment      data\n",
        "97           0  19.87261\n",
        "196          0   1.20387"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given that our model is a DPM we can\n",
      "compute\n",
      "\u2013 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b1\n",
      "\ud835\udc58\n",
      "- data at tree \ud835\udc47\ud835\udc58 was generated from\n",
      "the same cluster.\n",
      "\u2013 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b1\n",
      "\ud835\udc58 = \u222b \ud835\udc5d \ud835\udc37\ud835\udc58 \ud835\udf03 \ud835\udc5d \ud835\udf03 \ud835\udefd \ud835\udc51\ud835\udf03\n",
      "\u2013 Easy to compute if the model has conjugacy\n",
      "\n",
      "\n",
      "\ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b2\n",
      "\ud835\udc58\n",
      "- \ud835\udc37\ud835\udc58was generated from two or\n",
      "more components defining partitions\n",
      "consistent with trees \ud835\udc47\ud835\udc56 \ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc47\ud835\udc57\n",
      "\u2013 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b2\n",
      "\ud835\udc58 = \ud835\udc43 \ud835\udc37\ud835\udc56 \ud835\udc47\ud835\udc56 \ud835\udc43 \ud835\udc37\ud835\udc57 \ud835\udc47\ud835\udc57)\n",
      "\u2013 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc47\ud835\udc58 = \ud835\udf0b\ud835\udc58\ud835\udc5d \ud835\udc37\ud835\udc58 \ud835\udc3b\ud835\udc58\n",
      "1 + 1 \u2212 \ud835\udf0b\ud835\udc58 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b2\n",
      "\ud835\udc58\n",
      "\u2022 \ud835\udf0b\ud835\udc58 = \ud835\udc5d(\ud835\udc3b\ud835\udc58\n",
      "1\n",
      ")"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code the probability of the initial 2 points\n",
      "from scipy.stats import norm\n",
      "\n",
      "x_value = 1.20387 + 1.20387\n",
      "mu_0 = 1\n",
      "sigma_0 = 2\n",
      "n = 2\n",
      "\n",
      "def D_k (x_value, mu_0, sigma_0, n):\n",
      "    post_mu = (mu_0*1.0/np.power(sigma_0,2) + x_value*1.0/np.power(sigma_0,2))/(1.0/np.power(sigma_0,2)+n*1.0/np.power(sigma_0,2))\n",
      "    post_var = 1.0/(1.0/power(sigma_0,2) + n*1.0/power(sigma_0,2))\n",
      "    post_sigma = np.power(post_var,0.5)\n",
      "    return norm.pdf(x_value, loc = 3, scale = 5)\n",
      "\n",
      "print D_k(x_value, mu_0, sigma_0, n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0792306639672\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "def hcluster(data, features):\n",
      "    #cluster the rows of the \"features\" matrix\n",
      "    distances=[]\n",
      "    currentclustid=-1\n",
      "    dim = data.shape[0]\n",
      "    \n",
      "    newDic = zip(range(dat.shape[0]), dat[:,0])\n",
      "    newDic[3][0]\n",
      "\n",
      "    # clusters are initially just the individual rows\n",
      "    clust = range(0,dim)\n",
      "    while len(clust) > 1:\n",
      "        for i in range(len(clust)):\n",
      "            for j in range(i+1,len(clust)):\n",
      "                if ((i,j) not in distances == TRUE): \n",
      "                    distances.append((i,j))\n",
      "                    \n",
      "                d = distance()\n",
      "'''\n",
      "    while len(clust)>1:\n",
      "        lowestpair=(0,1)\n",
      "        closest=distance(clust[0].vec,clust[1].vec)\n",
      "\n",
      "        # loop through every pair looking for the smallest distance\n",
      "        for i in range(len(clust)):\n",
      "            for j in range(i+1,len(clust)):\n",
      "                # distances is the cache of distance calculations\n",
      "                if (clust[i].id,clust[j].id) not in distances: \n",
      "                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)\n",
      "\n",
      "                d=distances[(clust[i].id,clust[j].id)]\n",
      "\n",
      "                if d < 0.5:\n",
      "                    closest=d\n",
      "                    lowestpair=(i,j)\n",
      "\n",
      "        # calculate the average of the two clusters\n",
      "        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2.0 for i in range(0,clust[0].vec)]\n",
      "\n",
      "        # create the new cluster\n",
      "        newcluster=cluster_node(array(mergevec),left=clust[lowestpair[0]],\n",
      "                             right=clust[lowestpair[1]],\n",
      "                             distance=closest,id=currentclustid)\n",
      "\n",
      "        # cluster ids that weren't in the original set are negative\n",
      "        currentclustid-=1\n",
      "        del clust[lowestpair[1]]\n",
      "        del clust[lowestpair[0]]\n",
      "\n",
      "        clust.append(newcluster)\n",
      "        \n",
      "'''\n",
      "hcluster(dat, features=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'TRUE' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-156-aa93d9f06230>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m '''\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mhcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-156-aa93d9f06230>\u001b[0m in \u001b[0;36mhcluster\u001b[1;34m(data, features)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdistances\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTRUE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                     \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: global name 'TRUE' is not defined"
       ]
      }
     ],
     "prompt_number": 156
    }
   ],
   "metadata": {}
  }
 ]
}