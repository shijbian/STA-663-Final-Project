{
 "metadata": {
  "name": "",
  "signature": "sha256:0a955c5b134eb0d1d4e7939da97d1dbc7fb22779a2d0a9452f6a688e7ab122a6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bayesian Hierarchical Clustering \n",
      "=============\n",
      "\n",
      "#### STA 663 Computational Statistics in Python Final Project\n",
      "\n",
      "#### Shijia Bian\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Abstract\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Outline  \n",
      "\n",
      "+ #### Background  \n",
      "\n",
      "+ #### Traditional Hierarchical Clustering  \n",
      "\n",
      "+ #### Algorithm Debrief\n",
      "\n",
      "+ #### Case Study\n",
      "\n",
      "+ #### Limitation of Implemented Algorithm\n",
      "\n",
      "+ #### Comparison to Traditional Clustering Methods\n",
      "\n",
      "+ #### Further Improvement and Pseudo Code\n",
      "\n",
      "+ #### Conclusion \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Background\n",
      "\n",
      "State the research paper you are using. Describe the concept of the algorithm and why it is interesting and/or useful. If appropriate, describe the mathematical basis of the algorithm. Some potential topics for the backgorund include:\n",
      "\n",
      "- What problem does it address? \n",
      "- What are known and possible applications of the algorithm? \n",
      "- What are its advantages and disadvantages relative to other algorithms?\n",
      "- How will you use it in your research?\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Traditional Hierarchical Clustering  \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Algorithm Debrief\n",
      "\n",
      "#### Diagram\n",
      "![alt text](https://raw.githubusercontent.com/shijbian/STA-663-Final-Project/master/April%2023/nodeGraph.png)\n",
      "\n",
      "#### Notation  \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\mathcal{D} = \\{\\bf{x}^{(1)}, \\ldots, \\bf{x}^{(n)} \\}$: entire data set.\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $T_i$: subtree $i$.  \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\mathcal{D}_i$: data set in subtree $i$.\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $T_i \\cup T_j \\Rightarrow T_k \\rightarrow \\mathcal{D}_i \\cup \\mathcal{D}_j$: tree $T_i$ and tree $T_j$ merge to become a new tree $T_k$. \n",
      "\n",
      "#### Hypothesis Testing\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Null Hypothesis $\\mathcal{H}_1^k$**: all data in $\\mathcal{D}_k$ are i.i.d generated from the same probabilistic model $P(\\bf{x}|\\theta)$.  \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Alternative Hypothesis $\\mathcal{H}_2^k$**: data in $\\mathcal{D}_k$ are from two or more clusters.\n",
      "\n",
      "#### Marginal Likelihood for the Hypothesis\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Likelihood for Null Hypothesis:** data at tree $\\mathcal{D}_k$ is generated from the same cluster\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $P(\\mathcal{D}_k|H_1^k)= \\int P(\\mathcal{D}_k|\\theta) P(\\theta|\\beta) \\mathcal{d}\\theta$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Likelihood for Alternative Hypothesis:** data at tree $\\mathcal{D}_k$ is generated from different cluster\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $P(\\mathcal{D}_k|H_2^k)=P(\\mathcal{D}_i|T_i)P(\\mathcal{D}_j|T_j)$  \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  **Marginal Probability of the Data in Tree $T_k$:**\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $P(\\mathcal{D}_k|T_k)=\\pi_kP(\\mathcal{D}_k|H^k_1)+(1-\\pi_k)P(\\mathcal{D}_k|H^k_2)$  \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $\\pi_k = P(H^k_1)$\n",
      "\n",
      "#### Posterial Likelihood for the Hypothesis\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **$r_k=\\frac{\\pi_kp(\\mathcal{D}_k)|\\mathcal{H}_1^k}{\\pi_kP(\\mathcal{D}_k|H^k_1)+(1-\\pi_k)P(\\mathcal{D}_k|H^k_2)}$**\n",
      "\n",
      "#### Pseudocode for General Implementation\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **input** data $\\mathcal{D} = {x^{(1)}, x^{(2)}, \\ldots, x^{(n)}}$, model $p(x|\\theta)$, prior $p(\\theta|\\beta)$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **initialize: ** number of clusters $\\mathcal{c}=\\mathcal{n}$ for $i = 1, \\ldots, n$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **while** $\\mathcal{c}>1$ **do**:\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Find the pair $\\mathcal{D}_i$ and $\\mathcal{D}_j$ with the highest probability of the merged hypothesis:\n",
      " $$\\mathcal{r}_k = \\frac{\\pi_k p(\\mathcal{D}_k|\\mathcal{H}_1^k)}{p(\\mathcal{D}_k|\\mathcal{T}_k)}$$\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Merge $\\mathcal{D}_k \\leftarrow \\mathcal{D}_i \\cup \\mathcal{D}_j$, $\\mathcal{T}_k \\leftarrow (\\mathcal{T}_i, \\mathcal{T}_j)$  \n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Delete $\\mathcal{D}_i$ and $\\mathcal{D}_j$, $c \\leftarrow c-1$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **end while**\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **output: ** Bayesian mixture model where each tree node is a mixture component  \n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The tree can be cut at points where $\\mathcal{r}_k<0.5$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Case Study I: Gaussion Distribution with Unknown Mean and Known Precision\n",
      "\n",
      "In this case study, assume that the data are from two normal distributions with unknown mean and known variance.  \n",
      "\n",
      "$$X_1 \\sim \\mathcal{N}(\\mu_1,1) \\text{ and } X_2 \\sim \\mathcal{N}(\\mu_2,1)$$\n",
      "\n",
      "The prior for $\\mu_1$ and $\\mu_2$ is:  \n",
      "\n",
      "$$\\mu_1,\\mu_2 \\sim N(1,1)$$\n",
      "\n",
      "This setup can accomodate the algorithm from the perspectives below:\n",
      "\n",
      "+ the dataset can be normalized through the formula for the standard normal, i.e. it has mean zero and a unit variance;\n",
      "+ each observation $x^{(i)}$ is independnt and generated from different Gaussian distributions.\n",
      "+ the realizations of each variable j, ${x_j^{(i)}}_{j=1}^{n_k}$ in cluster $\\mathcal{D}_k$ are independent and identically distributed and drawn from Gaussian distribution with unknown mean $\\mu_j$ and precision $\\sigma_j^2$, and the prior on $(\\mu_j,\\sigma_j^{-2})$ is a normal-gamma distribution with hyperparameter $\\mu_0,\\sigma_0,\\beta_0,\\kappa$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "$$P(\\mathcal{D}|H_1)= \\int f(x|\\mu)f(\\mu) \\mathcal{d}\\mu = \\int_{-\\infty}^{\\infty} \\bigg[\\frac{1}{\\sigma_0 \\sqrt{2\\pi}}exp(-\\frac{(\\mu-\\mu_0)^2}{2\\sigma_0^2})\\bigg]\\bigg[(\\frac{1}{\\sigma \\sqrt{s\\pi}})^n exp(-\\frac{n(\\bar{x}-\\mu)^2}{2\\sigma^2})   \\bigg]\\mathcal{d}\\mu$$\n",
      "\n",
      "\n",
      "$$P(\\mathcal{D}|H_2)= \\int f(x|\\mu)f(\\mu) \\mathcal{d}\\mu = \\int_{-\\infty}^{\\infty} \\bigg[\\frac{1}{\\sigma_0 \\sqrt{2\\pi}}exp(-\\frac{(\\mu-\\mu_0)^2}{2\\sigma_0^2})\\bigg]\\bigg[(\\frac{1}{\\sigma \\sqrt{s\\pi}})^n exp(-\\frac{n(\\bar{x}-\\mu)^2}{2\\sigma^2})   \\bigg]\\mathcal{d}\\mu$$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import scipy.stats as stats\n",
      "from IPython.core.pylabtools import figsize\n",
      "import numpy as np\n",
      "figsize(12.5, 4)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "%matplotlib inline\n",
      "import scipy.stats as stats\n",
      "from IPython.core.pylabtools import figsize\n",
      "import numpy as np\n",
      "figsize(12.5, 4)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "import itertools\n",
      "\n",
      "import numpy as np\n",
      "from scipy import linalg\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "\n",
      "from sklearn import mixture\n",
      "\n",
      "import operator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Revised Algorithm \n",
      "\n",
      "+ **Step 1: Data Simulation:** \n",
      "simulate n data from two normal distribution: N(0, 1) and N(20, 1). This two cluster are distinguishable from each other. The default setup is 50% from the cluster 0 and 50% from the cluster 1;\n",
      "\n",
      "+ **Step 2: Initialization:** \n",
      "Initialize the data by extracting one pair of the data from each of the 2 clusters.\n",
      "\n",
      "+ **Step 3: Actual Algorithm:** \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Step 1: Data Simulation\n",
      "\n",
      "Data are simulated from two normal distribution:\n",
      "\n",
      "$$X_1 \\sim \\mathcal{N}(\\mu_1,1) \\text{ and } X_2 \\sim \\mathcal{N}(\\mu_2,1)$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean = (1,20)\n",
      "cov = [[1,0],[0,1]]\n",
      "n=5\n",
      "dat = np.random.multivariate_normal(mean,cov,n)\n",
      "print dat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  0.68118983  21.03808654]\n",
        " [  0.94751333  19.16913061]\n",
        " [  1.93553648  19.62907725]\n",
        " [  0.7170251   20.56803499]\n",
        " [  1.73156416  19.34427461]]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reshape the dataset to be a 20*1 \n",
      "data = dat.reshape((n*2, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can visualize the plots as below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(data, bins=20, color=\"k\", histtype=\"stepfilled\", alpha=0.8)\n",
      "plt.title(\"Histogram of the dataset\")\n",
      "plt.ylim([0, None])\n",
      "print data[:10], \"...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  0.26812886]\n",
        " [ 20.32297587]\n",
        " [  0.11428491]\n",
        " [ 21.92112071]\n",
        " [  1.82169658]\n",
        " [ 20.80214341]\n",
        " [  0.64154061]\n",
        " [ 21.12156267]\n",
        " [  0.71413739]\n",
        " [ 19.70727213]] ...\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAuAAAAEKCAYAAABT6eBwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f0eb82eb310>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymc as pm\n",
      "\n",
      "p = pm.Uniform(\"p\", 0, 1)\n",
      "\n",
      "assignment = pm.Categorical(\"assignment\", [p, 1 - p], size=data.shape[0])\n",
      "print \"prior assignment, with p = %.2f:\" % p.value\n",
      "print assignment.value[:10], \"...\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "prior assignment, with p = 0.69:\n",
        "[0 0 0 0 0 0 1 1 0 1] ...\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print assignment.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 0 0 1 1 0 1]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "n=5\n",
      "value = np.array([assignment.value])\n",
      "value = value.reshape((n*2,1)).reshape(-1)\n",
      "df = pd.DataFrame({'data': data.reshape(-1),\n",
      "                   'Assignment': value}, index=range(0,n*2))\n",
      "df['Assignment'] = df['Assignment'].astype(object)\n",
      "grouped = df.groupby(\"Assignment\")\n",
      "# mean for the two assigned groups respectively \n",
      "grouped.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Assignment</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  9.423498</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 13.823458</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                 data\n",
        "Assignment           \n",
        "0            9.423498\n",
        "1           13.823458"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is the data frame of the sampled n*2 data from 2 different normal distribution\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Assignment</th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td>  0.268129</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0</td>\n",
        "      <td> 20.322976</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td>  0.114285</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0</td>\n",
        "      <td> 21.921121</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td>  1.821697</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 0</td>\n",
        "      <td> 20.802143</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 1</td>\n",
        "      <td>  0.641541</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 1</td>\n",
        "      <td> 21.121563</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 0</td>\n",
        "      <td>  0.714137</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 1</td>\n",
        "      <td> 19.707272</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "  Assignment       data\n",
        "0          0   0.268129\n",
        "1          0  20.322976\n",
        "2          0   0.114285\n",
        "3          0  21.921121\n",
        "4          0   1.821697\n",
        "5          0  20.802143\n",
        "6          1   0.641541\n",
        "7          1  21.121563\n",
        "8          0   0.714137\n",
        "9          1  19.707272"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Slice the two data frames\n",
      "# df_0 has the data labeled 0\n",
      "# df_1 has the data labeled 1\n",
      "\n",
      "df_0 = df.loc[df['Assignment'] == 0]\n",
      "df_1 = df.loc[df['Assignment'] == 1]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data frame that is assigned 0\n",
      "df_0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Assignment</th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td>  0.268129</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0</td>\n",
        "      <td> 20.322976</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td>  0.114285</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0</td>\n",
        "      <td> 21.921121</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td>  1.821697</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 0</td>\n",
        "      <td> 20.802143</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 0</td>\n",
        "      <td>  0.714137</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "  Assignment       data\n",
        "0          0   0.268129\n",
        "1          0  20.322976\n",
        "2          0   0.114285\n",
        "3          0  21.921121\n",
        "4          0   1.821697\n",
        "5          0  20.802143\n",
        "8          0   0.714137"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data frame that is assigned 1\n",
      "df_1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Assignment</th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 1</td>\n",
        "      <td>  0.641541</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 1</td>\n",
        "      <td> 21.121563</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 1</td>\n",
        "      <td> 19.707272</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "  Assignment       data\n",
        "6          1   0.641541\n",
        "7          1  21.121563\n",
        "9          1  19.707272"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rows_0_v: random select two data from df_0\n",
      "\n",
      "# rows_0: the random 2 index assigned as 0\n",
      "rows_0 = np.random.choice(df_0.index.values, 2, replace = False)\n",
      "\n",
      "# sampled_df_0: the corresponding rows on the two index\n",
      "sampled_df_0 = df.ix[rows_0]\n",
      "\n",
      "# rows_0_v: extract the index only\n",
      "rows_0_v = rows_0.reshape(-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### Do the same thing as above for index 0\n",
      "# rows_1_v: random select two data from df_1\n",
      "rows_1 = np.random.choice(df_1.index.values, 2, replace = False)\n",
      "sampled_df_1 = df.ix[rows_1]\n",
      "rows_1_v = rows_1.reshape(-1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampled_df_0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Assignment</th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 0</td>\n",
        "      <td> 18.476423</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 0</td>\n",
        "      <td> -0.530422</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "  Assignment       data\n",
        "9          0  18.476423\n",
        "6          0  -0.530422"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampled_df_1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Assignment</th>\n",
        "      <th>data</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 1</td>\n",
        "      <td> 22.635347</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 1</td>\n",
        "      <td>  0.439438</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "  Assignment       data\n",
        "5          1  22.635347\n",
        "8          1   0.439438"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given that our model is a DPM we can\n",
      "compute\n",
      "\u2013 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b1\n",
      "\ud835\udc58\n",
      "- data at tree \ud835\udc47\ud835\udc58 was generated from\n",
      "the same cluster.\n",
      "\u2013 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b1\n",
      "\ud835\udc58 = \u222b \ud835\udc5d \ud835\udc37\ud835\udc58 \ud835\udf03 \ud835\udc5d \ud835\udf03 \ud835\udefd \ud835\udc51\ud835\udf03\n",
      "\u2013 Easy to compute if the model has conjugacy\n",
      "\n",
      "\n",
      "\ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b2\n",
      "\ud835\udc58\n",
      "- \ud835\udc37\ud835\udc58was generated from two or\n",
      "more components defining partitions\n",
      "consistent with trees \ud835\udc47\ud835\udc56 \ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc47\ud835\udc57\n",
      "\u2013 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b2\n",
      "\ud835\udc58 = \ud835\udc43 \ud835\udc37\ud835\udc56 \ud835\udc47\ud835\udc56 \ud835\udc43 \ud835\udc37\ud835\udc57 \ud835\udc47\ud835\udc57)\n",
      "\u2013 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc47\ud835\udc58 = \ud835\udf0b\ud835\udc58\ud835\udc5d \ud835\udc37\ud835\udc58 \ud835\udc3b\ud835\udc58\n",
      "1 + 1 \u2212 \ud835\udf0b\ud835\udc58 \ud835\udc43 \ud835\udc37\ud835\udc58 \ud835\udc3b2\n",
      "\ud835\udc58\n",
      "\u2022 \ud835\udf0b\ud835\udc58 = \ud835\udc5d(\ud835\udc3b\ud835\udc58\n",
      "1\n",
      ")"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code the probability of the initial 2 points\n",
      "from scipy.stats import norm\n",
      "\n",
      "x_value = 1.20387 + 1.20387\n",
      "mu_0 = 1\n",
      "sigma_0 = 2\n",
      "n = 2\n",
      "\n",
      "def D_k (x_value, mu_0, sigma_0, n):\n",
      "    post_mu = (mu_0*1.0/np.power(sigma_0,2) + x_value*1.0/np.power(sigma_0,2))/(1.0/np.power(sigma_0,2)+n*1.0/np.power(sigma_0,2))\n",
      "    post_var = 1.0/(1.0/power(sigma_0,2) + n*1.0/power(sigma_0,2))\n",
      "    post_sigma = np.power(post_var,0.5)\n",
      "    return norm.pdf(x_value, loc = 3, scale = 5)\n",
      "\n",
      "print D_k(x_value, mu_0, sigma_0, n)\n",
      "init_index = np.append(rows_0_v, rows_1_v)\n",
      "print init_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0792306639672\n",
        "[5 2 7 6]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# store the index that has been taken\n",
      "init_index = np.append(rows_0_v, rows_1_v)\n",
      "\n",
      "# store the list of values the cluster 0 should take\n",
      "clust0_v = np.append([df.ix[init_index[0],1]], [df.ix[init_index[1],1]])\n",
      "print clust0_v\n",
      "# store the list of values the cluster 1 should take\n",
      "clust1_v = np.append([df.ix[init_index[2],1]], [df.ix[init_index[3],1]])\n",
      "print clust1_v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 20.80214341   0.11428491]\n",
        "[ 21.12156267   0.64154061]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 9\n",
      "tempx_clust0_v = np.append([clust0_v], [df.ix[i,1]])\n",
      "print tempx_clust0_v.size\n",
      "alterlike = D_k (sum(tempx_clust0_v),  mu_0 = 1, sigma_0 = 1, n = 1)\n",
      "print alterlike"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n",
        "4.04288333446e-14\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![alt text](https://raw.githubusercontent.com/shijbian/STA-663-Final-Project/master/April%2023/nodeGraph.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Self-design Algorithm\n",
      "\n",
      "+ **Select two pairs of points. Each of them are located separately in the two clusters.**\n",
      "\n",
      "+ **Define the function D_k**\n",
      "\n",
      "+ **Define the function hcluster:**\n",
      "    \n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; t_clust_0: initialized $T_i$  \n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; t_clust_1: initialized $T_j$  \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function will take into the parameters below:  \n",
      "\n",
      "+ data: the entire data set;\n",
      "+ n: the number of data;\n",
      "+ pi_0: the probability of locating in the first cluster\n",
      "+ pi_1: the probability of locating in the second cluster\n",
      "+ init_index_0: the index of data that are initialized in the first cluster\n",
      "+ init_index_1: the index of data that are initialized in the second cluster\n",
      "+ clust0_v: data that are initialized in the first cluster\n",
      "+ clust1_v: data that are initialized in the second cluster"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implement the integration:\n",
      "\n",
      "$$P(\\mathcal{D}|H_1)= \\int f(x|\\mu)f(\\mu) \\mathcal{d}\\mu = \\int_{-\\infty}^{\\infty} \\bigg[\\frac{1}{\\sigma_0 \\sqrt{2\\pi}}exp(-\\frac{(\\mu-\\mu_0)^2}{2\\sigma_0^2})\\bigg]\\bigg[(\\frac{1}{\\sigma \\sqrt{s\\pi}})^n exp(-\\frac{n(\\bar{x}-\\mu)^2}{2\\sigma^2})   \\bigg]\\mathcal{d}\\mu$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.integrate import quad\n",
      "\n",
      "def mu_int(sigma_null, mu_null, sigma, N, X):\n",
      "    k1 = 1.0 / (sigma_null * math.sqrt(2*math.pi))\n",
      "    s1 = -1.0 / (2 * sigma_null * sigma_null)\n",
      "    \n",
      "    k2 = 1.0 / (sigma * math.sqrt(2*math.pi))\n",
      "    s2 = -1.0 / (2 * sigma * sigma)\n",
      "    \n",
      "    x_bar = X*1.0/N\n",
      "    \n",
      "    def f(mu):\n",
      "        return (k1 * math.exp(s1 * (mu - mu_null)*(mu - mu_null)))*(k2 * math.exp(s2 * N*(mu - x_bar)*(mu - x_bar)))\n",
      "    return f\n",
      "\n",
      "#quad(mu_int(10, 10, 10, 10, 105), -inf, inf)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "(0.012014901279871065, 8.225789967887554e-09)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code the probability of the initial 2 points\n",
      "from scipy.stats import norm\n",
      "\n",
      "x_value = 1.20387 + 1.20387\n",
      "mu_0 = 1\n",
      "sigma_0 = 2\n",
      "n = 2\n",
      "\n",
      "def D_k_2 (x_value, mu_0, sigma_0, n):\n",
      "    post_mu = (mu_0*1.0/np.power(sigma_0,2) + x_value*1.0/np.power(sigma_0,2))/(1.0/np.power(sigma_0,2)+n*1.0/np.power(sigma_0,2))\n",
      "    post_var = 1.0/(1.0/power(sigma_0,2) + n*1.0/power(sigma_0,2))\n",
      "    post_sigma = np.power(post_var,0.5)\n",
      "    return norm.pdf(x_value, loc = 3, scale = 5)\n",
      "\n",
      "print D_k(x_value, mu_0, sigma_0, n)\n",
      "init_index = np.append(rows_0_v, rows_1_v)\n",
      "print init_index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "init_index_0 = init_index[:2]\n",
      "init_index_0 = init_index[2:]\n",
      "\n",
      "def hcluster(data, n, pi_0, pi_1, init_index_0, init_index_1, clust0_v, clust1_v):\n",
      "    closed = 0.0\n",
      "    # initialize the t_node for clust 0: 2 initial selected values\n",
      "    t_clust_0 = D_k (sum(clust0_v),  mu_0 = 1, sigma_0=1, n = tempx_clust0_v.size)\n",
      "    \n",
      "    # initialize the t_node for clust 1: 2 initial selected values\n",
      "    t_clust_1 = D_k (sum(clust1_v),  mu_0 = 10, sigma_0=1, n = tempx_clust0_v.size)\n",
      "    \n",
      "    # go through all the points\n",
      "    for i in range(n):\n",
      "            \n",
      "        closest_lik = 0.0\n",
      "            \n",
      "        clust_0 = dict()\n",
      "\n",
      "        clust_1 = dict()\n",
      "            \n",
      "        # traverse all the points and pick the one that makes the likelihood to be bigger than \n",
      "        # another\n",
      "        for i in range(n):\n",
      "        \n",
      "            closest_lik = 0.0\n",
      "            \n",
      "            clust_0 = dict()\n",
      "\n",
      "            clust_1 = dict()\n",
      "            \n",
      "            # traverse of the left array\n",
      "            # i must not exist in the already exist init_index\n",
      "            if (i not in init_index == TRUE):\n",
      "                # temp add the x value to the existing picked x\n",
      "                tempx_clust0_v = np.append([clust0_v], [df.ix[i,1]])\n",
      "                tempx_clust1_v = np.append([clust1_v], [df.ix[i,1]])\n",
      "                    \n",
      "                # likeli for alternative under clust 0\n",
      "                lik_alt_0 = pi_0 * D_k (sum(tempx_clust0_v),  mu_0 = 1, sigma_0=1, n = tempx_clust0_v.size)\n",
      "                    \n",
      "                    # likeli for alternative under clust 1\n",
      "                lik_alt_1 = D_k (sum(tempx_clust1_v),  mu_0 = 10, sigma_0=1, n = tempx_clust1_v.size)\n",
      "\n",
      "                    # likeli for null under clust 0\n",
      "                lik_null_1 = (1-pi_0) * t_clust_0 * lik_alt_1\n",
      "                    \n",
      "                if lik_alt_0 > lik_null_1:\n",
      "                    post = lik_alt_0 + lik_alt_1\n",
      "                    clust_0.update({j:post})\n",
      "                else:\n",
      "                    post = lik_alt_0 + lik_alt_1\n",
      "                    clust_1.update({j:post})\n",
      "                    \n",
      "                # select the max likelihood from the two lists\n",
      "                maxLik_0 = max(clust_0.iterkeys(), key=lambda k: stats[k])\n",
      "                maxLik_1 = max(clust_1.iterkeys(), key=lambda k: stats[k])\n",
      "                if (maxLik_0>maxLik_1):\n",
      "                    # updated tode number\n",
      "                    t_clust_0 = clust_0[maxLik_0]\n",
      "                    # add the x-value \n",
      "                    clust0_v.append(maxLik_0)\n",
      "                else:\n",
      "                    t_clust_1 = clust_1[maxLik_1]\n",
      "                    clust1_v.append(maxLik_1)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The limit of this algorithm\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "init_index_0 = init_index[:2]\n",
      "init_index_0 = init_index[2:]\n",
      "mu_int(sigma_null, mu_null, sigma, N, X)\n",
      "\n",
      "def hcluster(data, n, mu_0, mu_1, sigma, mu_null, sigma_null, pi, init_index_0, init_index_1, clust0_v, clust1_v):\n",
      "    closed = 0.0\n",
      "    # initialize the T_i for clust 0: 2 initial selected values\n",
      "    N0 = clust0_v.size\n",
      "    t_clust_0 = quad(mu_int(sigma_null, mu_null, sigma, N0, clust0_v), -inf, inf)[1]\n",
      "    \n",
      "    # initialize the T_j for clust 1: 2 initial selected values\n",
      "    N1 = clust1_v.size\n",
      "    t_clust_0 = quad(mu_int(sigma_null, mu_null, sigma, N1, clust1_v), -inf, inf)[1]\n",
      "    \n",
      "    # go through all the points\n",
      "    for i in range(n):\n",
      "            \n",
      "        closest_lik = 0.0\n",
      "            \n",
      "        clust_0 = dict()\n",
      "\n",
      "        clust_1 = dict()\n",
      "            \n",
      "        # traverse all the points and pick the one that makes the likelihood to be bigger than \n",
      "        # another\n",
      "        for i in range(n):\n",
      "        \n",
      "            closest_lik = 0.0\n",
      "            \n",
      "            clust_0 = dict()\n",
      "\n",
      "            clust_1 = dict()\n",
      "            \n",
      "            # traverse of the left array\n",
      "            # i must not exist in the already exist init_index\n",
      "            if (i not in init_index == TRUE):\n",
      "                # temp add the x value to the existing picked x\n",
      "                tempx_clust0_v = np.append([clust0_v], [df.ix[i,1]])\n",
      "                tempx_clust1_v = np.append([clust1_v], [df.ix[i,1]])\n",
      "                    \n",
      "                # likeli for alternative under clust 0\n",
      "                lik_alt_0 = pi_0 * D_k (sum(tempx_clust0_v),  mu_0 = 1, sigma_0=1, n = tempx_clust0_v.size)\n",
      "                    \n",
      "                    # likeli for alternative under clust 1\n",
      "                lik_alt_1 = D_k (sum(tempx_clust1_v),  mu_0 = 10, sigma_0=1, n = tempx_clust1_v.size)\n",
      "\n",
      "                    # likeli for null under clust 0\n",
      "                lik_null_1 = (1-pi_0) * t_clust_0 * lik_alt_1\n",
      "                    \n",
      "                if lik_alt_0 > lik_null_1:\n",
      "                    post = lik_alt_0 + lik_alt_1\n",
      "                    clust_0.update({j:post})\n",
      "                else:\n",
      "                    post = lik_alt_0 + lik_alt_1\n",
      "                    clust_1.update({j:post})\n",
      "                    \n",
      "                # select the max likelihood from the two lists\n",
      "                maxLik_0 = max(clust_0.iterkeys(), key=lambda k: stats[k])\n",
      "                maxLik_1 = max(clust_1.iterkeys(), key=lambda k: stats[k])\n",
      "                if (maxLik_0>maxLik_1):\n",
      "                    # updated tode number\n",
      "                    t_clust_0 = clust_0[maxLik_0]\n",
      "                    # add the x-value \n",
      "                    clust0_v.append(maxLik_0)\n",
      "                else:\n",
      "                    t_clust_1 = clust_1[maxLik_1]\n",
      "                    clust1_v.append(maxLik_1)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tryF (df, val1, val2):\n",
      "    return df.iat[val1, val2]\n",
      "\n",
      "print tryF(df, 0,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clust=dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " clust.update({3:4})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clust.update({'xyy':4})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print clust"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'xyy': 4, 3: 4}\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import operator\n",
      "stats = {'a':1000, 'b':3000, 'c': 100}\n",
      "ss = max(stats.iterkeys(), key=lambda k: stats[k])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats[ss]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "3000"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}